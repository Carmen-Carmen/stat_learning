log_reg.model = glm(fml, data = data[train_filter, ],
family = binomial)
test_set = data[-train_filter, ]
log_reg.prob = predict(log_reg.model, test_set, type = "response")
log_reg.pred = rep(FALSE, nrow(test_set))
log_reg.pred[log_reg.prob > .5] = TRUE
accuracy = mean(test_set[[response]] == log_reg.pred)
return(accuracy)
}
log_reg_pred(Boston, predictors, "is_high_crime")
lda_pred = function(data, predictors, response) {
fml = as.formula(paste(response,
paste(predictors, collapse = "+"), sep = "~"))
train_filter = get_random_subset_indices(data, subset_fraction = .9)
lda.model = lda(fml, data = data, subset = train_filter)
test_set = data[-train_filter, ]
lda.pred = predict(lda.model, test_set)
accuracy = mean(test_set[[response]] == lda.pred$class)
return(accuracy)
}
lda_pred(Boston, predictors, "is_high_crime")
knn_pred = function(data, predictors, response) {
set.seed(1)
train_filter = get_random_subset_indices(data, subset_fraction = .9)
X = as.data.frame(scale(data[predictors]))
train.X = X[train_filter, ]
# train.X = scale(train.X)
train.Y = data[train_filter, response]
test.X = X[-train_filter, ]
# test.X = scale(test.X)
best_k = 0
highest_accuracy = 0
test_set = data[-train_filter, ]
for (k_val in 1:50) {
knn.pred = knn(train.X, test.X, train.Y, k = k_val)
accuracy = mean(knn.pred == test_set[[response]])
if (accuracy > highest_accuracy) {
highest_accuracy = accuracy
best_k = k_val
}
}
res = data.frame("accuracy"= highest_accuracy,
"k"= best_k)
return(res)
}
knn_pred(Boston, predictors[1:2], "is_high_crime")
nb_pred = function(data, predictors, response) {
fml = as.formula(paste(response,
paste(predictors, collapse = "+"), sep = "~"))
train_filter = get_random_subset_indices(data, subset_fraction = .9)
nb.model = naiveBayes(fml, data = data, subset = train_filter)
test_set = data[train_filter, ]
nb.pred = predict(nb.model, test_set)
accuracy = mean(nb.pred == test_set[[response]])
return(accuracy)
}
nb_pred(Boston, predictors, "is_high_crime")
# predictors is a vector of strings, i.e. colnames
classify_prediction = function(data, predictors, response) {
set.seed(1)
# logistic regression
log_reg_res = log_reg_pred(data, predictors, response)
# lda
lda_res = lda_pred(data, predictors, response)
# knn
knn_res = knn_pred(data, predictors, response)$accuracy
# naive Bayes
nb_res = nb_pred(data, predictors, response)
res = data.frame("log_reg" = log_reg_res,
"lda" = lda_res,
"knn" = knn_res,
"nb" = nb_res)
return(res)
}
classify_prediction(Boston, predictors, "is_high_crime")
accuracy_list = data.frame()
for (i in 1:length(predictors)) {
predictors_temp = predictors[1:i]
accuracy_list = rbind(accuracy_list,
classify_prediction(Boston,
predictors_temp,
"is_high_crime"))
}
plot(x = 1:nrow(accuracy_list), y = accuracy_list$log_reg,
type = "o", ylim = range(.6, 1), col = "red",
xlab = "number of predictors",
ylab = "overall accuracy")
lines(x = 1:nrow(accuracy_list), y = accuracy_list$lda,
type = "o", col = "blue")
lines(x = 1:nrow(accuracy_list), y = accuracy_list$knn,
type = "o", col = "green")
lines(x = 1:nrow(accuracy_list), y = accuracy_list$nb,
type = "o", col = "orange")
legend("bottomright", legend = c("logistic regression",
"linear discriminant analysis",
"k-nearest neighbors",
"naive Bayes"),
col = c("red", "blue", "green", "orange"),
lty = 1, pch = 1)
knn_pred = function(data, predictors, response) {
set.seed(1)
train_filter = get_random_subset_indices(data, subset_fraction = .9)
X = as.data.frame(scale(data[predictors]))
train.X = X[train_filter, drop=FALSE]
# train.X = scale(train.X)
train.Y = data[train_filter, response]
test.X = X[-train_filter, ]
# test.X = scale(test.X)
best_k = 0
highest_accuracy = 0
test_set = data[-train_filter, ]
for (k_val in 1:50) {
knn.pred = knn(train.X, test.X, train.Y, k = k_val)
accuracy = mean(knn.pred == test_set[[response]])
if (accuracy > highest_accuracy) {
highest_accuracy = accuracy
best_k = k_val
}
}
res = data.frame("accuracy"= highest_accuracy,
"k"= best_k)
return(res)
}
knn_pred(Boston, predictors[1:2], "is_high_crime")
knn_pred = function(data, predictors, response) {
set.seed(1)
train_filter = get_random_subset_indices(data, subset_fraction = .9)
X = as.data.frame(scale(data[predictors]))
train.X = X[train_filter,, drop=FALSE]
# train.X = scale(train.X)
train.Y = data[train_filter, response]
test.X = X[-train_filter, ]
# test.X = scale(test.X)
best_k = 0
highest_accuracy = 0
test_set = data[-train_filter, ]
for (k_val in 1:50) {
knn.pred = knn(train.X, test.X, train.Y, k = k_val)
accuracy = mean(knn.pred == test_set[[response]])
if (accuracy > highest_accuracy) {
highest_accuracy = accuracy
best_k = k_val
}
}
res = data.frame("accuracy"= highest_accuracy,
"k"= best_k)
return(res)
}
knn_pred(Boston, predictors[1:2], "is_high_crime")
knn_pred = function(data, predictors, response) {
set.seed(1)
train_filter = get_random_subset_indices(data, subset_fraction = .9)
X = as.data.frame(scale(data[predictors]))
train.X = X[train_filter, , drop=FALSE]
# train.X = scale(train.X)
train.Y = data[train_filter, response]
test.X = X[-train_filter, , drop=FALSE]
# test.X = scale(test.X)
best_k = 0
highest_accuracy = 0
test_set = data[-train_filter, ]
for (k_val in 1:50) {
knn.pred = knn(train.X, test.X, train.Y, k = k_val)
accuracy = mean(knn.pred == test_set[[response]])
if (accuracy > highest_accuracy) {
highest_accuracy = accuracy
best_k = k_val
}
}
res = data.frame("accuracy"= highest_accuracy,
"k"= best_k)
return(res)
}
knn_pred(Boston, predictors[1:2], "is_high_crime")
# predictors is a vector of strings, i.e. col_names
classify_prediction = function(data, predictors, response) {
set.seed(1)
# logistic regression
log_reg_res = log_reg_pred(data, predictors, response)
# lda
lda_res = lda_pred(data, predictors, response)
# knn
knn_res = knn_pred(data, predictors, response)$accuracy
# naive Bayes
nb_res = nb_pred(data, predictors, response)
res = data.frame("log_reg" = log_reg_res,
"lda" = lda_res,
"knn" = knn_res,
"nb" = nb_res)
return(res)
}
classify_prediction(Boston, predictors, "is_high_crime")
accuracy_list = data.frame()
for (i in 1:length(predictors)) {
predictors_temp = predictors[1:i]
accuracy_list = rbind(accuracy_list,
classify_prediction(Boston,
predictors_temp,
"is_high_crime"))
}
plot(x = 1:nrow(accuracy_list), y = accuracy_list$log_reg,
type = "o", ylim = range(.6, 1), col = "red",
xlab = "number of predictors",
ylab = "overall accuracy")
lines(x = 1:nrow(accuracy_list), y = accuracy_list$lda,
type = "o", col = "blue")
lines(x = 1:nrow(accuracy_list), y = accuracy_list$knn,
type = "o", col = "green")
lines(x = 1:nrow(accuracy_list), y = accuracy_list$nb,
type = "o", col = "orange")
legend("bottomright", legend = c("logistic regression",
"linear discriminant analysis",
"k-nearest neighbors",
"naive Bayes"),
col = c("red", "blue", "green", "orange"),
lty = 1, pch = 1)
library(ISLR2)
library(MASS)
library(class)
library(e1071)
attach(Boston)
summary(Boston)
is_high_crime = rep(FALSE, nrow(Boston))
is_high_crime[Boston$crim >= median(Boston$crim)] = TRUE
summary(is_high_crime)
# ?Boston
par(mfrow = c(2, 2))
for (p in names(Boston)) {
if (p != "crim") {
plot(x = as.factor(is_high_crime), y = Boston[[p]],
xlab = "is high crime rate", ylab = p)
}
}
par(mfrow = c(1, 1))
# order the predictors by their correlation with is_high_crim
predictors = Boston[,-1]
cor_list = sapply(predictors, function(x) abs(cor(x, is_high_crime)))
sorted_cor_list = sort(cor_list, decreasing = TRUE)
sorted_cor_list
Boston$is_high_crime = is_high_crime
get_random_subset_indices = function(data, subset_fraction) {
set.seed(1)
subset_size = round(nrow(data) * subset_fraction)
subset_indices = sample(seq_len(nrow(data)), size = subset_size)
return(subset_indices)
}
predictors = names(sorted_cor_list)
log_reg_pred = function(data, predictors, response) {
fml = as.formula(paste(response,
paste(predictors, collapse = "+"), sep = "~"))
train_filter = get_random_subset_indices(data, subset_fraction = .9)
log_reg.model = glm(fml, data = data[train_filter, ],
family = binomial)
test_set = data[-train_filter, ]
log_reg.prob = predict(log_reg.model, test_set, type = "response")
log_reg.pred = rep(FALSE, nrow(test_set))
log_reg.pred[log_reg.prob > .5] = TRUE
accuracy = mean(test_set[[response]] == log_reg.pred)
return(accuracy)
}
log_reg_pred(Boston, predictors, "is_high_crime")
lda_pred = function(data, predictors, response) {
fml = as.formula(paste(response,
paste(predictors, collapse = "+"), sep = "~"))
train_filter = get_random_subset_indices(data, subset_fraction = .9)
lda.model = lda(fml, data = data, subset = train_filter)
test_set = data[-train_filter, ]
lda.pred = predict(lda.model, test_set)
accuracy = mean(test_set[[response]] == lda.pred$class)
return(accuracy)
}
lda_pred(Boston, predictors, "is_high_crime")
knn_pred = function(data, predictors, response) {
set.seed(1)
train_filter = get_random_subset_indices(data, subset_fraction = .9)
X = as.data.frame(scale(data[predictors]))
train.X = X[train_filter, , drop=FALSE]
# train.X = scale(train.X)
train.Y = data[train_filter, response]
test.X = X[-train_filter, , drop=FALSE]
# test.X = scale(test.X)
best_k = 0
highest_accuracy = 0
test_set = data[-train_filter, ]
for (k_val in 1:50) {
knn.pred = knn(train.X, test.X, train.Y, k = k_val)
accuracy = mean(knn.pred == test_set[[response]])
if (accuracy > highest_accuracy) {
highest_accuracy = accuracy
best_k = k_val
}
}
res = data.frame("accuracy"= highest_accuracy,
"k"= best_k)
return(res)
}
knn_pred(Boston, predictors[1:2], "is_high_crime")
nb_pred = function(data, predictors, response) {
fml = as.formula(paste(response,
paste(predictors, collapse = "+"), sep = "~"))
train_filter = get_random_subset_indices(data, subset_fraction = .9)
nb.model = naiveBayes(fml, data = data, subset = train_filter)
test_set = data[train_filter, ]
nb.pred = predict(nb.model, test_set)
accuracy = mean(nb.pred == test_set[[response]])
return(accuracy)
}
nb_pred(Boston, predictors, "is_high_crime")
# predictors is a vector of strings, i.e. col_names
classify_prediction = function(data, predictors, response) {
set.seed(1)
# logistic regression
log_reg_res = log_reg_pred(data, predictors, response)
# lda
lda_res = lda_pred(data, predictors, response)
# knn
knn_res = knn_pred(data, predictors, response)$accuracy
# naive Bayes
nb_res = nb_pred(data, predictors, response)
res = data.frame("log_reg" = log_reg_res,
"lda" = lda_res,
"knn" = knn_res,
"nb" = nb_res)
return(res)
}
classify_prediction(Boston, predictors, "is_high_crime")
accuracy_list = data.frame()
for (i in 1:length(predictors)) {
predictors_temp = predictors[1:i]
accuracy_list = rbind(accuracy_list,
classify_prediction(Boston,
predictors_temp,
"is_high_crime"))
}
plot(x = 1:nrow(accuracy_list), y = accuracy_list$log_reg,
type = "o", ylim = range(.6, 1), col = "red",
xlab = "number of predictors",
ylab = "overall accuracy")
lines(x = 1:nrow(accuracy_list), y = accuracy_list$lda,
type = "o", col = "blue")
lines(x = 1:nrow(accuracy_list), y = accuracy_list$knn,
type = "o", col = "green")
lines(x = 1:nrow(accuracy_list), y = accuracy_list$nb,
type = "o", col = "orange")
legend("bottomright", legend = c("logistic regression",
"linear discriminant analysis",
"k-nearest neighbors",
"naive Bayes"),
col = c("red", "blue", "green", "orange"),
lty = 1, pch = 1)
library(ISLR2)
library(MASS)
library(class)
library(e1071)
attach(Boston)
summary(Boston)
is_high_crime = rep(FALSE, nrow(Boston))
is_high_crime[Boston$crim >= median(Boston$crim)] = TRUE
summary(is_high_crime)
par(mfrow = c(2, 2))
library(ISLR2)
# 5.3.1 The Validation Set Approach
set.seed(1)
train = sample(392, 196)
lm.fit = lm(mpg ~ horsepower, data = Auto, subset = train)
attach(Auto)
# calculate MSE with the linear model
lm.MSE = mean(((mpg - predict(lm.fit, Auto))[-train]) ^ 2)
lm.MSE # 23.26601
lm.fit2 = lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)
# calculate MSE with the quadratic model
lm.MSE2 = mean(((mpg - predict(lm.fit2, Auto))[-train]) ^ 2)
lm.MSE2 # 18.71646
lm.fit3 = lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)
summary(lm.fit3)
# MSE with the cubic model
lm.MSE3 = mean(((mpg - predict(lm.fit3, Auto))[-train]) ^ 2)
lm.MSE3 # 18.79401
# try on a different training set
set.seed(2)
train = sample(392, 196) # from 392 observations, randomly choose 196 as the training set
lm.fit = lm(mpg ~ horsepower, data = Auto, subset = train)
lm.fit2 = lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)
lm.fit3 = lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)
lm.MSE = mean(((mpg - predict(lm.fit, Auto))[-train]) ^ 2)
lm.MSE2 = mean(((mpg - predict(lm.fit2, Auto))[-train]) ^ 2)
lm.MSE3 = mean(((mpg - predict(lm.fit3, Auto))[-train]) ^ 2)
to_print = sprintf("linear MSE: %.2f\nquadratic MSE: %.2f\ncubic MSE: %.2f", lm.MSE, lm.MSE2, lm.MSE3)
cat(to_print) # use concatenate to output strings containing "\n"
# redraw the plot on the textbook
poly_num = c(seq(1, 10))
validation_set_df = data.frame(poly_num)
for (i in seq(1, 10)) {
set.seed(i)
train = sample(nrow(Auto), nrow(Auto) / 2)
MSE_list = c()
for (k in poly_num) {
# print(k)
lm.fit = lm(mpg ~ poly(horsepower, k), data = Auto, subset = train)
lm.MSE = mean(((mpg - predict(lm.fit, Auto))[-train]) ^ 2)
MSE_list = c(MSE_list, lm.MSE)
}
validation_set_df = cbind(validation_set_df, MSE_list)
}
plot(x = validation_set_df[,1], y = validation_set_df[,2],
xlab = "polynomial numbers", ylab = "MSE", type = "o",
ylim = range(15, 30))
for (i in seq(3, 10)) {
lines(x = validation_set_df[,1], y = validation_set_df[,i],
xlab = "polynomial numbers", ylab = "MSE", type = "o")
}
# 5.3.2 Leave-One-Out Cross-Validation, LOOCV
set.seed(2)
glm.fit = glm(mpg ~ horsepower, data = Auto,)
coef(glm.fit)
# (Intercept)  horsepower
# 39.9358610  -0.1578447
lm.fit = lm(mpg ~ horsepower, data = Auto)
coef(lm.fit)
library(boot)
cv.err = cv.glm(Auto, glm.fit)
cv.err$delta # 24.23151 24.23114
cv.errors = rep(0, 10)
for (i in 1 : 10) {
glm.fit = glm(mpg ~ poly(horsepower, i), data = Auto)
cv.errors[i] = cv.glm(Auto, glm.fit)$delta[1]
}
cv.errors # 24.23151 19.24821 19.33498 19.42443 19.03321 18.97864 18.83305 18.96115 19.06863 19.49093
# 5.3.3 K-Fold Cross-Validation
set.seed(17)
cv.error.10 = rep(0, 10)
for (i in seq(1, 10)) {
glm.fit = glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error.10[i] = cv.glm(Auto, glm.fit, K = 10)$delta[1]
print(cv.glm(Auto, glm.fit, K = 10)$delta)
# the first number is the standard k-fold CV estimate
# while the second is a bias-corrected one, slightly different
# [1] 24.08261 24.07523
# [1] 19.14276 19.13436
# [1] 19.31430 19.29461
# [1] 19.51186 19.47755
# [1] 19.19115 19.14911
# [1] 18.98648 18.94621
# [1] 18.78177 18.74373
# [1] 18.87421 18.83082
# [1] 19.11015 19.05006
# [1] 19.0269 18.9629
}
cv.error.10 # 24.27207 19.26909 19.34805 19.29496 19.03198 18.89781 19.12061 19.14666 18.87013 20.95520
# 5.3.4 The Bootstrap
# One of the great advantages of the bootstrap approach is that
# it can be applied in almost all situations.
# step 1: create a function that computes the statistic of interest
# take the investment returns as example
alpha.fn = function(data, index) {
X = data$X[index]
Y = data$Y[index]
(var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y))
}
alpha.fn(Portfolio, 1:100) # 0.5758321
# randomly select 100 observations from the range 1 to 100, with replacement
# equivalent to constructing a new bootstrap data set and recomputing ^α based on the new data set
set.seed(7)
alpha.fn(Portfolio, sample(100, 100, replace = T)) # 0.5385326
# implement the command by multiple times
boot(Portfolio, alpha.fn, R = 1000)
# Estimating the Accuracy of a Linear Regression Model
boot.fn = function(data, index) {
coef(lm(mpg ~ horsepower, data = data, subset = index))
}
boot.fn(Auto, 1:392)
set.seed(1)
boot.fn(Auto, sample(392, 392, replace = T))
# (Intercept)  horsepower
# 40.3404517  -0.1634868
boot.fn(Auto, sample(392, 392, replace = T))
# compute the errors of 100 bootstrap estimates
boot(Auto, boot.fn, 1000)
# ORDINARY NONPARAMETRIC BOOTSTRAP
#
# Call:
#   boot(data = Auto, statistic = boot.fn, R = 1000)
#
# Bootstrap Statistics :
#       original        bias    std. error
# t1* 39.9358610  0.0544513229 0.841289790
# t2* -0.1578447 -0.0006170901 0.007343073
summary(lm(mpg ~ horsepower, data = Auto))$coef
load("./5.R.Rdata")
setwd("~/Downloads/stat_learning/chapter_5/R")
load("./5.R.Rdata")
load("./5.R.Rdata")
load("~/Downloads/stat_learning/chapter_5/R/5.R.RData")
View(Xy)
lm.fit = glm(y ~ X1 + X2, data = Xy)
summary(lm.fit)
matplot(Xy, type="I")
matplot(Xy, type="l")
boot.fn = function(data, index) {
coef(lm(y ~ X1 + X2), data = data, subset = index)
}
boot(Xy, boot.fn, nrow(Xy) * 0.1)
boot.fn = function(data, index) {
coef(lm(y ~ X1 + X2, data = data, subset = index))
}
boot(Xy, boot.fn, nrow(Xy) * 0.1)
boot.out
plot(boot(Xy, boot.fn, nrow(Xy) * 0.1))
nrows(Xy)
nrow(Xy)
new.rows = c(1:100, 101:200, 201:300, 301:400, 401:500, 501:600, 601:700, 701:800, 801:900, 901:1000)
new.rows
